{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e85e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:32:14.764353Z",
     "iopub.status.busy": "2023-11-17T04:32:14.763742Z",
     "iopub.status.idle": "2023-11-17T04:32:41.228686Z",
     "shell.execute_reply": "2023-11-17T04:32:41.227467Z"
    },
    "papermill": {
     "duration": 26.477741,
     "end_time": "2023-11-17T04:32:41.231467",
     "exception": false,
     "start_time": "2023-11-17T04:32:14.753726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install torchsummary\n",
    "# %pip install torchgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a459699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3215514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969b0ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:32:41.250198Z",
     "iopub.status.busy": "2023-11-17T04:32:41.249893Z",
     "iopub.status.idle": "2023-11-17T04:33:00.479139Z",
     "shell.execute_reply": "2023-11-17T04:33:00.478171Z"
    },
    "papermill": {
     "duration": 19.241144,
     "end_time": "2023-11-17T04:33:00.481493",
     "exception": false,
     "start_time": "2023-11-17T04:32:41.240349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c175dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:00.506159Z",
     "iopub.status.busy": "2023-11-17T04:33:00.505846Z",
     "iopub.status.idle": "2023-11-17T04:33:10.774850Z",
     "shell.execute_reply": "2023-11-17T04:33:10.773918Z"
    },
    "papermill": {
     "duration": 10.284104,
     "end_time": "2023-11-17T04:33:10.777335",
     "exception": false,
     "start_time": "2023-11-17T04:33:00.493231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748328d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:11.839562Z",
     "iopub.status.busy": "2023-11-17T04:33:11.839244Z",
     "iopub.status.idle": "2023-11-17T04:33:11.951528Z",
     "shell.execute_reply": "2023-11-17T04:33:11.950624Z"
    },
    "papermill": {
     "duration": 0.127015,
     "end_time": "2023-11-17T04:33:11.953624",
     "exception": false,
     "start_time": "2023-11-17T04:33:11.826609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8f2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:11.978524Z",
     "iopub.status.busy": "2023-11-17T04:33:11.978236Z",
     "iopub.status.idle": "2023-11-17T04:33:11.990393Z",
     "shell.execute_reply": "2023-11-17T04:33:11.989641Z"
    },
    "papermill": {
     "duration": 0.027012,
     "end_time": "2023-11-17T04:33:11.992493",
     "exception": false,
     "start_time": "2023-11-17T04:33:11.965481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetCustom(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b975c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.017102Z",
     "iopub.status.busy": "2023-11-17T04:33:12.016817Z",
     "iopub.status.idle": "2023-11-17T04:33:12.308287Z",
     "shell.execute_reply": "2023-11-17T04:33:12.307353Z"
    },
    "papermill": {
     "duration": 0.306037,
     "end_time": "2023-11-17T04:33:12.310186",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.004149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_path = \"train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = 'train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927f980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.334549Z",
     "iopub.status.busy": "2023-11-17T04:33:12.334265Z",
     "iopub.status.idle": "2023-11-17T04:33:12.655721Z",
     "shell.execute_reply": "2023-11-17T04:33:12.654588Z"
    },
    "papermill": {
     "duration": 0.336065,
     "end_time": "2023-11-17T04:33:12.657918",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.321853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = 'train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d03341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.684107Z",
     "iopub.status.busy": "2023-11-17T04:33:12.683415Z",
     "iopub.status.idle": "2023-11-17T04:33:12.688730Z",
     "shell.execute_reply": "2023-11-17T04:33:12.687853Z"
    },
    "papermill": {
     "duration": 0.02092,
     "end_time": "2023-11-17T04:33:12.690872",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.669952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = DatasetCustom(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (256,256),\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395917c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:12.715773Z",
     "iopub.status.busy": "2023-11-17T04:33:12.715480Z",
     "iopub.status.idle": "2023-11-17T04:33:55.513504Z",
     "shell.execute_reply": "2023-11-17T04:33:55.512413Z"
    },
    "papermill": {
     "duration": 42.813372,
     "end_time": "2023-11-17T04:33:55.516034",
     "exception": false,
     "start_time": "2023-11-17T04:33:12.702662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291b8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:55.543422Z",
     "iopub.status.busy": "2023-11-17T04:33:55.543121Z",
     "iopub.status.idle": "2023-11-17T04:33:56.698418Z",
     "shell.execute_reply": "2023-11-17T04:33:56.697583Z"
    },
    "papermill": {
     "duration": 1.1714,
     "end_time": "2023-11-17T04:33:56.700870",
     "exception": false,
     "start_time": "2023-11-17T04:33:55.529470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282af1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.728401Z",
     "iopub.status.busy": "2023-11-17T04:33:56.728085Z",
     "iopub.status.idle": "2023-11-17T04:33:56.735884Z",
     "shell.execute_reply": "2023-11-17T04:33:56.734882Z"
    },
    "papermill": {
     "duration": 0.024157,
     "end_time": "2023-11-17T04:33:56.738018",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.713861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        assert image.shape[:2] == label.shape[:2]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cfb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.764418Z",
     "iopub.status.busy": "2023-11-17T04:33:56.763924Z",
     "iopub.status.idle": "2023-11-17T04:33:56.771880Z",
     "shell.execute_reply": "2023-11-17T04:33:56.770794Z"
    },
    "papermill": {
     "duration": 0.023247,
     "end_time": "2023-11-17T04:33:56.773829",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.750582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.VerticalFlip(p=0.4),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27432c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.802769Z",
     "iopub.status.busy": "2023-11-17T04:33:56.802418Z",
     "iopub.status.idle": "2023-11-17T04:33:56.809969Z",
     "shell.execute_reply": "2023-11-17T04:33:56.808843Z"
    },
    "papermill": {
     "duration": 0.025438,
     "end_time": "2023-11-17T04:33:56.812628",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.787190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(images_data))\n",
    "val_size = len(images_data) - train_size\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transformation)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384bbbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.840509Z",
     "iopub.status.busy": "2023-11-17T04:33:56.840032Z",
     "iopub.status.idle": "2023-11-17T04:33:56.845857Z",
     "shell.execute_reply": "2023-11-17T04:33:56.845024Z"
    },
    "papermill": {
     "duration": 0.021413,
     "end_time": "2023-11-17T04:33:56.847858",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.826445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bc628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.873729Z",
     "iopub.status.busy": "2023-11-17T04:33:56.873445Z",
     "iopub.status.idle": "2023-11-17T04:33:56.879243Z",
     "shell.execute_reply": "2023-11-17T04:33:56.878266Z"
    },
    "papermill": {
     "duration": 0.021032,
     "end_time": "2023-11-17T04:33:56.881370",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.860338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f16ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:33:56.909180Z",
     "iopub.status.busy": "2023-11-17T04:33:56.908905Z",
     "iopub.status.idle": "2023-11-17T04:34:28.660655Z",
     "shell.execute_reply": "2023-11-17T04:34:28.659204Z"
    },
    "papermill": {
     "duration": 31.769224,
     "end_time": "2023-11-17T04:34:28.664160",
     "exception": false,
     "start_time": "2023-11-17T04:33:56.894936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    name = \"run_6\",\n",
    "    project = \"PolypSegment\",\n",
    "    resume=\"allow\"\n",
    ")\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475f647",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96a2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T04:34:41.288532Z",
     "iopub.status.busy": "2023-11-17T04:34:41.288090Z",
     "iopub.status.idle": "2023-11-17T06:30:57.923850Z",
     "shell.execute_reply": "2023-11-17T06:30:57.922709Z"
    },
    "papermill": {
     "duration": 6976.659187,
     "end_time": "2023-11-17T06:30:57.926139",
     "exception": false,
     "start_time": "2023-11-17T04:34:41.266952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_loss = 999\n",
    "\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += criterion(outputs.float(),labels.long()).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"New best checkpoint saved!\")\n",
    "        \n",
    "    epoch_bar.update(1)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader)})\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d38e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:30:58.032350Z",
     "iopub.status.busy": "2023-11-17T06:30:58.032038Z",
     "iopub.status.idle": "2023-11-17T06:31:00.872244Z",
     "shell.execute_reply": "2023-11-17T06:31:00.871278Z"
    },
    "papermill": {
     "duration": 2.894935,
     "end_time": "2023-11-17T06:31:00.874256",
     "exception": false,
     "start_time": "2023-11-17T06:30:57.979321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model.pth',weights_only=True))\n",
    "checkpoint = torch.load('model.pth_1', weights_only=True)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50451997",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /S /Q prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a72ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:00.985676Z",
     "iopub.status.busy": "2023-11-17T06:31:00.985081Z",
     "iopub.status.idle": "2023-11-17T06:31:02.056924Z",
     "shell.execute_reply": "2023-11-17T06:31:02.055715Z"
    },
    "papermill": {
     "duration": 1.128229,
     "end_time": "2023-11-17T06:31:02.059381",
     "exception": false,
     "start_time": "2023-11-17T06:31:00.931152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d379c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:02.172392Z",
     "iopub.status.busy": "2023-11-17T06:31:02.171534Z",
     "iopub.status.idle": "2023-11-17T06:31:28.541107Z",
     "shell.execute_reply": "2023-11-17T06:31:28.540319Z"
    },
    "papermill": {
     "duration": 26.427994,
     "end_time": "2023-11-17T06:31:28.543403",
     "exception": false,
     "start_time": "2023-11-17T06:31:02.115409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir(\"test/test\"):\n",
    "    img_path = os.path.join(\"test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (256, 256))\n",
    "    transformed = val_transformation(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341dddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:28.652348Z",
     "iopub.status.busy": "2023-11-17T06:31:28.651596Z",
     "iopub.status.idle": "2023-11-17T06:31:31.862445Z",
     "shell.execute_reply": "2023-11-17T06:31:31.861295Z"
    },
    "papermill": {
     "duration": 3.267238,
     "end_time": "2023-11-17T06:31:31.864765",
     "exception": false,
     "start_time": "2023-11-17T06:31:28.597527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = 'prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bbb84",
   "metadata": {
    "papermill": {
     "duration": 0.061661,
     "end_time": "2023-11-17T06:31:31.988681",
     "exception": false,
     "start_time": "2023-11-17T06:31:31.927020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Infer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaeb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:32.111178Z",
     "iopub.status.busy": "2023-11-17T06:31:32.110378Z",
     "iopub.status.idle": "2023-11-17T06:31:32.114788Z",
     "shell.execute_reply": "2023-11-17T06:31:32.113834Z"
    },
    "papermill": {
     "duration": 0.064946,
     "end_time": "2023-11-17T06:31:32.116715",
     "exception": false,
     "start_time": "2023-11-17T06:31:32.051769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.jit import load\n",
    "# model = UNet()\n",
    "# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# checkpoint = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a016d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:32.233647Z",
     "iopub.status.busy": "2023-11-17T06:31:32.232872Z",
     "iopub.status.idle": "2023-11-17T06:31:32.237057Z",
     "shell.execute_reply": "2023-11-17T06:31:32.236169Z"
    },
    "papermill": {
     "duration": 0.064741,
     "end_time": "2023-11-17T06:31:32.239149",
     "exception": false,
     "start_time": "2023-11-17T06:31:32.174408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a0dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:31:32.352942Z",
     "iopub.status.busy": "2023-11-17T06:31:32.352627Z",
     "iopub.status.idle": "2023-11-17T06:31:32.356742Z",
     "shell.execute_reply": "2023-11-17T06:31:32.355849Z"
    },
    "papermill": {
     "duration": 0.063202,
     "end_time": "2023-11-17T06:31:32.358667",
     "exception": false,
     "start_time": "2023-11-17T06:31:32.295465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# new_state_dict = OrderedDict()\n",
    "# for k, v in checkpoint['model'].items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# # load params\n",
    "# model.load_state_dict(new_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 4002781,
     "sourceId": 6983304,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7164.401292,
   "end_time": "2023-11-17T06:31:35.350673",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-17T04:32:10.949381",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
